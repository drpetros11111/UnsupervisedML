{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn Text\n",
    "Demo of text processing functionality in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create messages\n",
    "List of 3 messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset\n",
    "list_message = [\"Call me soon\", \"CALL to win\", \"Pick me up soon\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process text: using sklearn CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of count vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "# Perform word counts\n",
    "Xfit = vectorizer.fit_transform(list_message)\n",
    "# Generate feature matrix (transform so sample axis is along columns)\n",
    "X = Xfit.toarray().T\n",
    "print(\"X: \\n{}\".format(X))\n",
    "# list words in vocabulary (turn into numpy array)\n",
    "words = np.array(vectorizer.get_feature_names())\n",
    "print(\"Words: {}\".format(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process text: using sklearn TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance of vectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "# Perform word counts\n",
    "Xfit_tfidf = vectorizer_tfidf.fit_transform(list_message)\n",
    "# Generate feature matrix (transform so sample axis is along columns)\n",
    "X_tfidf = Xfit_tfidf.toarray().T\n",
    "print(\"X_tfidf: \\n{}\".format(X_tfidf))\n",
    "# list words in vocabulary (turn into numpy array)\n",
    "words_tfidf = np.array(vectorizer_tfidf.get_feature_names())\n",
    "print(\"Words: {}\".format(words_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How is tfidf matrix calculated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term frequency matrix is X produced by CountVectorizer\n",
    "# Document frequency is number of documents in which a word appears\n",
    "print(\"Term Frequency: \\n{}\".format(X))\n",
    "df = np.sum(X>0,axis=1,keepdims=True)\n",
    "print(\"Document Frequency: \\n{}\".format(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse Document Frequency\n",
    "ndoc = len(list_message)\n",
    "idf = np.log((ndoc+1)/(df+1))+1\n",
    "print(\"idf: \\n{}\".format(idf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf\n",
    "tfidf = X*idf\n",
    "# scale so each column has length 1\n",
    "tfidf_norm = np.sqrt(np.sum(np.square(tfidf),axis=0,keepdims=0))\n",
    "tfidf = tfidf/tfidf_norm\n",
    "print(\"X_tfidf using sklearn: \\n{}\".format(X_tfidf))\n",
    "print(\"Computed tfidf \\n{}\".format(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
